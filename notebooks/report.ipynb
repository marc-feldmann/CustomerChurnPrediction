{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Keep in mind while writing up:*\n",
    "\n",
    "- *Be concise! Less is more - the fully story is in the source code for those interested.*\n",
    "- *Be deliberate about: What to highlight in which section (e.g., “this dataset was special due to its high number of variables”…)*\n",
    "- *Work with visuals and only exceptionally with code. Refer to GitHub, dump code there, the technical people will go there. And (hiring) managers will only read the write-up.*\n",
    "- *Optimize business value, not model performance! Time/Resource constraints, ….*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Report\n",
    "# **Preventing Customer Churn with Artificial Neural Networks**\n",
    "*Disclaimer: This mock project report serves educational purposes only. The data is public (https://www.kdd.org/kdd-cup/view/kdd-cup-2009/Data). The author has no relationship with mentioned parties.* \n",
    "***\n",
    "### **Executive Summary (max. 7 sentences)**\n",
    "Situation (1 sentence based on 1.)\n",
    "<br>\n",
    "Complication (1 sentence based on 1.)\n",
    "<br>\n",
    "Solution (1 sentence based on 2.)\n",
    "<br>\n",
    "Recommendations including Solutions' Business Value Add (1-3 sentences based on 3.)\n",
    "\"much buzz around ANN, let's test that here\"\n",
    "***\n",
    "### **Report Structure**\n",
    "[Include nice + simple process visualization!]\n",
    "1. Business Problem Statement\n",
    "2. Technical Solution\n",
    "<br>    *2.1. Technical Problem Statement*\n",
    "<br>    *2.2. Exploratory Data Analysis*\n",
    "<br>    *2.3. Data Preprocessing*\n",
    "<br>    *2.4. Model Selection (incl. Optimization)*\n",
    "<br>    *2.5. Final Model Evaluation*\n",
    "<br>    *2.6. Future Optimization Potentials*\n",
    "3. Business Recommendations\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Business Problem Statement**\n",
    "For French telecommunication provider Orange, customer retention is critical. This is because retaining customers is much cheaper than the alternative: losing a customer and their revenues *plus* having additional costs for acquiring a new customer. However, Orange lacks an automated, scalable, and data-driven method for predicting customer churn that would allow Orange to initiate retention measures before customers leave. Thus, Orange requested a proof-of-concept for a predictive model that can help identify customers who will likely churn. More specifically, given their widely reported success, Orange is interested in exploring the potential of \"deep learning\" models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Technical Solution**\n",
    "- for visualization inspirations see here: https://towardsdatascience.com/predict-customer-churn-the-right-way-using-pycaret-8ba6541608ac\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.1. Technical Solution: Technical Problem Statement*\n",
    "The business problem, as put by our client Orange, is \"to predict customer churn\". This problem requires translation into a better specified, technical problem to be solvable using mathematical-statistical methods.\n",
    "\n",
    "To begin with, it is important to understand that the problem we want to solve is a binary classification problem: given the data available for any particular customer (e.g., age, gender, purchased services, average call duration), we want our model to assign this customer to one of the two classes \"churn\"/\"no churn\". Understanding that in this project we solve a classification problem has two main implications for the entire technical solution we build:\n",
    "\n",
    "1) *Choice of an adequate model class*. In a typical data science project, we would train models from many different model classes (e.g., logistic regression classifiers, trees, support vector machines) and select the best performing models (or a combination of them in an *ensemble*) for deployment. In this project, however, Orange, the client, has specified upfront that they want a \"deep learning\" model, which in more precise technical terms means an artificial neural network (ANN) with more than one hidden layer. Since we want the ANN's output to always be either \"churn\" or \"no churn\", its output layer must contain a single neuron with an activation function (e.g., ReLU, sigmoid) able to translate continuous into binary values (1/0, \"churn\"/\"no churn\").\n",
    "\n",
    "2) *Choice of an adequate optimization metric*. An optimization metric helps us assess how \"good\" our developed classification model is and improve it. The perhaps most intuitive metric would be the model's *accuracy*. Accuracy tells us in which percentage of cases a classification model's predictions (\"churn\"/\"no churn\") are true (that is, correctly predict what customers will actually do). However, we can infer from the business context that the classes \"churn\"/\"no churn\" we are interested in are *imbalanced*: only a minority of all customers will churn in any given time period. We can thus expect many more customers to be in the \"no churn\" rather than the \"churn\" class. Accuracy will thus be a bad metric to optimize: the model could 'cheat' and predict \"no churn\" in 100% of the cases, and never detect a single churning customer, and still have awesome accuracy. In presence of class imbalance, a metric more adequate to optimize is the *F1-score*. A high F1-score indicates not only that the model is able to correctly identify many of those customers which will in fact churn, but also that the model's \"churn\"-predictions are typically correct (two different things!).   \n",
    "\n",
    "All things considered, **the technical problem statement** we arrive at is to **maximize the F1-score in the churn prediction of Orange's customers by implementing an artificial neural network model with more than one hidden layer and an output layer with a single neuron including a binary activiation function**. \n",
    " \n",
    "\n",
    "Resources used:\n",
    "- Data: Orange has provided historical customer data (50,000 observations/customers; 230 features) for model optimization, selection, and evaluation. \n",
    "- Software: Python 3.8.5., main packages:\n",
    "    - Pandas, Numpy (for data wrangling)\n",
    "    - Keras/TensorFlow (for neural network modelling)\n",
    "    - Scikit-learn (for optimization/gridsearch automation)\n",
    "    - Matplotlib, Seaborn (for visualization)\n",
    "- Hardware: simple notebook\n",
    "\n",
    "Deliverable:\n",
    "-  source code in Python that can serve as proof of concept before deploying and putting into production (check vocabulary; for containerization also check this: https://github.com/Azure-Samples/MachineLearningSamples-TDSPUCIAdultIncome/blob/master/docs/deliverable_docs/ProjectReport.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.2. Technical Solution: Exploratory Data Analysis (EDA)*\n",
    "Now that we know precisely which technical problem we try to solve in this project, we try to familiarize ourselves a bit better with the historical customer data Orange has provided. This involves some basic overall checks (overall dataset structure, feature types, sparsity), but also analyses more focused on our target variable (= what we want to predict), that is, the class label vector \"churn\"/\"no churn\".\n",
    "\n",
    "#### Overall analyses\n",
    "\n",
    "#### Target variable analyses\n",
    "\n",
    "\n",
    "\n",
    "#### Key insights from EDA:\n",
    "\n",
    "- explicit ANN data requirements; EDA (= departing from that + nice visualizations of basic dataset properties)\n",
    "- highlight peculiarity of dataset: MANY NaNs, will be main challenge to handle these in a way not compromising churn predictions\n",
    "- varibles are anonymized\n",
    "- missing values/sparsity\n",
    "- class balance\n",
    "-  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.3. Technical Solution: Data Preprocessing*\n",
    "(e.g., data cleaning (data types, missing value handling), feature engineering, feature selection, dimensionality reduction, variable encoding, normalization, resampling...)\n",
    "\n",
    "- proceed from EDA main findings\n",
    "- optimization: \"Optimization of only thought about in terms of tuning hyperparamters; but also preprocessing includes many steps that can be done in different ways - meaning also has potential to optimize: read following in conjunction with \"diary\" to see what I have optimzied here and with which success: <br>\n",
    " - (X) Dropping all columns which have more than 80% missing values\n",
    " - (X) Increase test set size to 20%\n",
    " - (X) Do not resample at all but work with class weights\n",
    " - (X) NaN handling: try in addition to creating binary indicator variables per column\n",
    " - (X) impute with column-wise median\n",
    " - (X) impute with column-wise mode (in most cases this equals a zero imputation)\n",
    " - (X) impute with column-wise minimum\n",
    " - (X) impute with column-wise maximum\n",
    " - (X) impute with column-wise NaN frequency\n",
    " - Feature Engineering:\n",
    "   - (X) DO NOT create binary indicator variables per column to indicate NaNs\n",
    "   - add column containing rows' NaN frequencies\n",
    " - Remove outliers (before norm/stand)\n",
    " - go from feature normalization to Standardization, mind sparsity\n",
    "   - (X) MinMax (wie in v1, nur jetzt über SKlearn Method statt manuell, daher zum Test reproduziert; diesen Schritt jetzt auch erst nach Splitting eingebaut)\n",
    "   - (X) RobustScaler\n",
    "   - (X) PowerTransformer\n",
    " - (X) Train and Reduce dimensionality (e.g., PCA); feature\n",
    " selection would have benefit to be explanable, however, features\n",
    " anonymized anyways\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### *2.4. Technical Solution: Model Selection (incl. Optimization)*\n",
    "(Model Choice, Training, Validation, Optimization)\n",
    "split dataset, choose/apply model, compile/train models, optimize model (gridsearch, cross-validation, stratified y/n, ...)\n",
    "\n",
    "pick best model that comes out of gridsearch and train on entire dataset (while during gridsearch has been trained only on fraction while validation data had been held out)\n",
    "\n",
    "- specify neural network as \"Feed-forward neural network\" - why not recurrent, LSTM that can loop/have memory -given goal in this project is to probe the hypoe around \"deep learning\", unnecessary complexity\n",
    "- in write-up: reflect on fact neural networks / deep learning seem to be overhyped\n",
    "- see e.g.: Peter Roßbach: \"Neural Networks vs. Random Forests – Does it always have to be Deep Learning?\n",
    "- - make that explicit point of the write-up! \"test\" that!\n",
    "- show here that I know how to work with learning curves\n",
    "\n",
    "when looking at results, come back to earlier point, explain via clas imbalance\n",
    "come back to earlier point: \n",
    "- make it one main technical point in the article that high accuracy can be misleading (when? why?) - have to also check other measures\n",
    "- - includein write-up my reflections for using precision/recall instead of AUC (argue by importance to detect minority class relative to importance of TPs and FPs) (expl in simple language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.5. Technical Solution: Final Model Evaluation*\n",
    "Model Evaluation on 'Unseen' Data (simulate by priorly held out 'Test Data')\n",
    "- Do the results make sense?\n",
    "\n",
    "- show/compare how accuracy can be misleading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *2.6. Technical Solution: Future Optimization Potentials*\n",
    "(hier sammeln alles ich zeitlich nicht geschafft hab, aber für wichtig halte - um Kritik zu preempten)\n",
    "\n",
    "Schema: Potential - Umsetzungsaufwand - erwarteter Umsetzungseffekt auf Business Metric\n",
    "\n",
    "- version 2: optimization potentials (versus v1) to explore ceteris paribus:\n",
    "- not explored/limitations: only individually optimized, due to constraints in processing power and time, optimization dependencies between variables neglected\n",
    "- only narrow ranges in gridsearch covered, so sound change that only found local optima per parameter\n",
    "- potential: NaN imputation with means on subsets of rows: one could search powerful clustering criteria first and than impute cluster means\n",
    "- also: was using smaller dataset, large dataset with many more variables may allow to increase a classifier's precision/recall\n",
    "- Make sure to also compare to others' results - I seem to be already working at the upper boundary of what's possible on this dataset with ANNs!\n",
    "- optimization potential: in practice, one would normally traing many different models and select/stack the best; show somehow that I'm aware of that\n",
    "- (optimization potential: add and compare AUC: simple logistic regression, random forest, 'flat' neural network, XGBoost)\n",
    "- optimization potential: put data into an AWS instance and run there\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Business Recommendations**\n",
    "\"What do the generated insights/model urge us/allow us to do different next Monday, and which value (business metric!) will that generate?\"\n",
    "\n",
    "direkt aus auftrag (1.) ableiten. incl.:\n",
    "- (after implementing comparative models:) \"turns out, deep learning (might) not be best for this kind of problem; best practice computer vision, very large datasets; here: tree model such as XGboost or simple logistic regression better \n",
    "\n",
    "Good Example: https://www.kaggle.com/code/hamzaben/employee-churn-model-w-strategic-retention-plan/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0e858973d4b0767378b2a391e82dfc297a0e494a6ac1816312417e02d17e8ebb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
